# Tests should generate (and then clean up) any files they need for testing. No
# binary files should be included in the repository.

# Tests should generate (and then clean up) any files they need for testing. No
# binary files should be included in the repository.
from bluesky.plans import count
import json
import tempfile
import tifffile
from suitcase.tiff import export, SuitcaseTiffError
import event_model
import pytest


def events_data(RE, hw, det='det', event_type='events'):
    '''Generates data to be used for testing.

    Parameters
    ----------
    RE : object
        bluesky.RunEngine object to be used to generate the data.
    hw : object
        ophyd.sim.hw object from which to extract simulated detectors and
        motors.
    det : string
        The name of the detector to use to generate the data.
    event_type : string
        The event type to return (can be 'events', 'bulk_events' or
        'event_pages')

    Returns
    -------
    collector : list
        A list of (name, doc) tuple pairs generated by the run engine.
    expected : dict
        A dictionary with the schema:
            {'metadata': {'start': start_doc, 'stop': stop_doc,
                          'descriptors': {'primary': 'descriptor'}},
             'primary': {'seq_num': [], 'uid': [], 'time': [],
                         'timestamps': {det_name:[]},
                         'data': {det_name:[]}}}

        .. note::

            This schema was chosen as the API is very similar to the
            intake-databroker API
    '''

    # define the output lists and an internal list.
    collector = []
    event_list = []

    # define the collector function depending on the event_type
    if event_type == 'events':
        def collect(name, doc):
            collector.append((name, doc))
            if name == 'event':
                event_list.append(doc)
    elif event_type == 'event_pages':
        def collect(name, doc):
            if name == 'event':
                event_list.append(doc)
            elif name == 'stop':
                collector.append(('event_page',
                                  event_model.pack_event_page(*event_list)))
                collector.append((name, doc))
            else:
                collector.append((name, doc))
    elif event_type == 'bulk_events':
        def collect(name, doc):
            if name == 'event':
                event_list.append(doc)
            elif name == 'stop':
                collector.append(('bulk_event', {'primary': event_list}))
                collector.append((name, doc))
            else:
                collector.append((name, doc))
    else:
        raise UnknownEventType('Unknown event_type kwarg passed to '
                               'suitcase.tiff.events_data')

    # collect the documents
    RE.subscribe(collect)
    RE(count([hw.direct_img], 5))

    # create the expected dictionary from the documents
    docs = (doc for name, doc in collector)
    start, descriptor, *data_events, stop = docs
    expected = {}
    det_name = list(descriptor['data_keys'].keys())[0]  # There is only one
    expected['primary'] = {'data': {det_name: []}, 'seq_num': [], 'time': [],
                           'uid': [], 'timestamps': {'img': []}}
    for event in event_list:
        expected['primary']['data'][det_name].append(event['data'][det_name])
        expected['primary']['timestamps'][det_name].append(
            event['timestamps'][det_name])
        expected['primary']['seq_num'].append(event['seq_num'])
        expected['primary']['time'].append(event['time'])
        expected['primary']['uid'].append(event['uid'])

    expected['metadata'] = {'start': start, 'stop': stop,
                            'descriptors': {'primary': descriptor}}

    # ensure that the returned data is a built-in python type:
    for i, val in enumerate(expected['primary']['data'][det_name]):
        expected['primary']['data'][det_name][i] = event_model._sanitize_numpy(
            val)

    return collector, expected


def export_documents(export, collector):
    '''exports the data, then reloads it testing.

    Parameters
    ----------
    RE : object
        bluesky.RunEngine object to be used to generate the data.
    hw : object
        ophyd.sim.hw object from which to extract simulated detectors and
        motors.
    det : string
        The name of the detector to use to generate the data.
    event_type : string
        The event type to return (can be 'events', 'bulk_events' or
        'event_page')

    Returns
    -------
    actual : dict
        A dictionary with the schema generated by loading the exported data:
            {'metadata': {'start': start_doc, 'stop': stop_doc,
                          'descriptors': {'primary': 'descriptor'}},
             'primary': {'seq_num': [], 'uid': [], 'time': [],
                         'timestamps': {det_name:[]},
                         'data': {det_name:[]}}}

        .. note::

            This schema was chosen as the API is very similar to the
            intake-databroker API
    '''

    # define the output dictionary
    actual = {}

    # save the file with export
    with tempfile.NamedTemporaryFile(mode='w') as f:
        # We don't actually need f itself, just a filepath to template on.
        meta, *tiffs = export(collector, f.name)
    tiff, = tiffs

    # open the files and place the data in the output dictionary
    with open(meta) as f:
        actual = json.load(f)
    actual['primary']['data'] = {'img': tifffile.imread(tiff).tolist()}

    # This section is used to convert lists to tuples for the assert below
    for dims in actual['metadata']['start']['hints']['dimensions']:
        new_dims = []
        for dim in dims:
            if type(dim) is list:
                new_dims.append(tuple(dim))
            else:
                new_dims.append(dim)
        actual['metadata']['start']['hints']['dimensions'] = [tuple(new_dims)]

    return actual


def test_export_events(RE, hw):
    '''Test to see if suitcase.tiff.export() works on bulk_events
    '''
    # collect the data to be exported.
    collector, expected = events_data(RE, hw, det='direct_img',
                                      event_type='events')

    # export the data and return the round-trip loaded data for comparison
    actual = export_documents(export, collector)

    # perform the tests
    # check that both dicts have the same top level keys
    assert actual.keys() == expected.keys()
    # check that the start, stop and descriptor documents are the same
    assert actual['metadata'] == expected['metadata']
    # check that the data, uid, time, timestamps and seq_nums are the same
    assert actual['primary'] == expected['primary']


def test_export_bulk_events(RE, hw):
    '''Test to see if suitcase.tiff.export() works on bulk_events
    '''
    # collect the data to be exported.
    collector, expected = events_data(RE, hw, det='direct_img',
                                      event_type='bulk_events')

    # export the data and return the round-trip loaded data for comparison
    actual = export_documents(export, collector)

    # perform the tests
    # check that both dicts have the same top level keys
    assert actual.keys() == expected.keys()
    # check that the start, stop and descriptor documents are the same
    assert actual['metadata'] == expected['metadata']
    # check that the data, uid, time, timestamps and seq_nums are the same
    assert actual['primary'] == expected['primary']


def test_export_event_pages(RE, hw):
    '''Test to see if suitcase.tiff.export() works on event_pages
    '''
    # collect the data to be exported.
    collector, expected = events_data(RE, hw, det='direct_img',
                                      event_type='event_pages')

    # export the data and return the round-trip loaded data for comparison
    actual = export_documents(export, collector)

    # perform the tests
    # check that both dicts have the same top level keys
    assert actual.keys() == expected.keys()
    # check that the start, stop and descriptor documents are the same
    assert actual['metadata'] == expected['metadata']
    # check that the data, uid, time, timestamps and seq_nums are the same
    assert actual['primary'] == expected['primary']


class UnknownEventType(SuitcaseTiffError):
    ...
