# Tests should generate (and then clean up) any files they need for testing. No
# binary files should be included in the repository.

# Tests should generate (and then clean up) any files they need for testing. No
# binary files should be included in the repository.
import json
import tempfile
import tifffile
from . import export


def export_documents(export, collector):
    '''exports the data, then reloads it for testing.

    Parameters
    ----------
    RE : object
        bluesky.RunEngine object to be used to generate the data.
    hw : object
        ophyd.sim.hw object from which to extract simulated detectors and
        motors.
    det : string
        The name of the detector to use to generate the data.
    event_type : string
        The event type to return (can be 'events', 'bulk_events' or
        'event_page')

    Returns
    -------
    actual : dict
        A dictionary with the schema generated by loading the exported data:
            {'metadata': {'start': start_doc, 'stop': stop_doc,
                          'descriptors': {'primary':{
                                          'descriptor uid' :descriptor_doc}}},
             'streams': {'primary': {'seq_num': [], 'uid': [], 'time': [],
                         'descriptor':[], 'timestamps': {det_name:[]},
                         'data': {det_name:[]}}}}

        .. note::

            This schema was chosen as the API is very similar to the
            intake-databroker API
    '''

    # define the output dictionary

    # save the file with export to a temporary directory
    directory = tempfile.mkdtemp()
    artifacts = export(collector, directory, file_prefix='')

    # open the files and place the data in the output dictionary
    with open(str(artifacts['run_metadata'][0])) as f:
        actual = json.load(f)
    actual['streams']['primary']['data'] = {'img': tifffile.imread(
                                 str(artifacts['stream_data'][0])).tolist()}

    # This section is used to convert lists to tuples for the assert below
    for dims in actual['metadata']['start']['hints']['dimensions']:
        new_dims = []
        for dim in dims:
            if type(dim) is list:
                new_dims.append(tuple(dim))
            else:
                new_dims.append(dim)
        actual['metadata']['start']['hints']['dimensions'] = [tuple(new_dims)]

    return actual


def test_export(image_data):
    '''Test to see if suitcase.tiff.export() works on event, bulk_events or
    event_page documents.
    '''
    # collect the data to be exported.
    collector, expected = image_data

    # export the data and return the round-trip loaded data for comparison
    actual = export_documents(export, collector)

    # perform the tests
    # check that both dicts have the same top level keys
    assert actual.keys() == expected.keys()
    # check that the start, stop and descriptor documents are the same
    assert actual['metadata'] == expected['metadata']
    # check that the data, uid, time, timestamps and seq_nums are the same
    assert actual['streams']['primary'] == expected['streams']['primary']
